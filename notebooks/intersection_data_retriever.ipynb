{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e26cf022-2b73-46e2-b859-4d40c4d87f27",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sreejakr/openforest4d-forest-metrics/blob/main/notebooks/intersection_data_retriever.ipynb)\n",
    "\n",
    "# Download EPT Tiles in Jupyter Notebook\n",
    "\n",
    "This notebook automates the retrieval of lidar point‑cloud data for a specified region of interest by leveraging the USGS 3DEP Entwine Point Tile (EPT) service. It consists of two principal stages:\n",
    "\n",
    "1. **Intersection Polygon Computation**  \n",
    "   - Reads the master catalog of USGS 3DEP boundaries (EPSG:4326).  \n",
    "   - Selects two collections of interest (for example, pre‑ and post‑disturbance surveys) by their `name` fields.  \n",
    "   - Computes the geometric intersection of those two footprints, producing a single polygon that defines the exact overlap for which both datasets exist.  \n",
    "   - Writes this polygon to `data/placer_intersection.geojson` so that it can be used again later.\n",
    "\n",
    "2. **Buffered Tile Generation & EPT Download**  \n",
    "   - Reprojects the intersection polygon to UTM Zone 10N (EPSG:32610) so that all distances and areas are in meters. This target CRS can be changed to any other UTM zone by updating the EPSG code to match the study area’s longitude band.  \n",
    "   - Constructs a regular grid of square tiles (1000 m × 1000 m) covering the intersection, with a 20 m buffer around each tile to avoid missing edge points.  \n",
    "   - Iterates over each buffered tile:  \n",
    "     - Invokes PDAL’s EPT reader to request only the points falling within the buffered polygon.  \n",
    "     - Transforms the returned points into the target CRS.  \n",
    "     - Filters out empty tiles to minimize storage.  \n",
    "     - Writes each non‑empty tile as a compressed `.laz` file named by its lower‑left coordinates (e.g., `500000_4200000.laz`) into `Placer_2012_Tiled` (and a matching folder for the second collection).\n",
    "\n",
    "---\n",
    "\n",
    "## Motivation and Benefits\n",
    "\n",
    "- By computing the exact overlap of two surveys, analysis focuses only on areas where comparable data exist, eliminating gaps and reducing bias in comparisons.  \n",
    "- EPT queries return only the points within each buffered tile rather than downloading entire collections, greatly reducing bandwidth and local storage requirements.  \n",
    "- Breaking the intersection into buffered tiles enables parallel or distributed processing of large regions, accommodating very high‑resolution lidar datasets without memory exhaustion.  \n",
    "- All steps, from boundary loading through tile generation and download—are fully scripted, ensuring that any researcher can reproduce the same output simply by rerunning the notebook with identical parameters.  \n",
    "- The resulting `.laz` tiles feed directly into subsequent reprojection, tiling, metric extraction, and differencing workflows, forming the foundation of the OpenForest4D change‑detection pipeline.  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "##  Install Dependencies\n",
    "\n",
    "```bash\n",
    "# If needed, uncomment and run:\n",
    "# !pip install geopandas shapely pyproj pdal\n",
    "```\n",
    "\n",
    "##  User Configuration\n",
    "\n",
    "Edit these variables to match your environment:\n",
    "\n",
    "#### 1. Input GeoJSON with USGS 3DEP boundaries (EPSG:4326)\n",
    "- **Variable:** `boundaries_geojson`  \n",
    "- **Description:** Local path to the GeoJSON containing all 3DEP dataset footprints.  \n",
    "- **Note:**  The file has been included in `data/usgs_3dep_boundaries.geojson` (EPSG:4326).\n",
    "    Or get the latest from:    https://github.com/OpenTopography/Data_Catalog_Spatial_Boundaries/blob/main/usgs_3dep_boundaries.geojson\n",
    "\n",
    "#### 2. Feature Names to Intersect\n",
    "- **Variables:** `name_a`, `name_b`  \n",
    "- **Description:** Exact strings matching the `\"name\"` property in your GeoJSON. The script will extract only these two footprints and compute their geometric overlap.\n",
    "\n",
    "#### 3. Intersection Output Path\n",
    "- **Variable:** `intersection_geojson`  \n",
    "- **Description:** File path where the resulting intersection polygon GeoJSON will be saved. Load this in QGIS or feed it downstream.\n",
    "\n",
    "#### 4. EPT Endpoints for Each Dataset\n",
    "- **Variables:** `ept_path_a`, `ept_path_b`  \n",
    "- **Description:** The Entwine Point Tile (EPT) URLs for each 3DEP dataset. Prefix with `ept://` so PDAL can read them directly.  \n",
    "- **How to obtain:**  \n",
    "  1. Browse the AWS Public lidar S3 bucket:  \n",
    "     ```\n",
    "     https://s3-us-west-2.amazonaws.com/usgs-lidar-public/\n",
    "     ```  \n",
    "  2. Find your dataset folder (e.g. `CA_PlacerCo_2012`) and point PDAL at its `ept.json` URL:  \n",
    "     ```\n",
    "     ept://https://s3-us-west-2.amazonaws.com/usgs-lidar-public/CA_PlacerCo_2012/ept.json\n",
    "     ```  \n",
    "  3. Use that string in your `ept_path_*` variable.\n",
    "\n",
    "#### 5. Output Directories for Tiles\n",
    "- **Variables:** `output_dir_a`, `output_dir_b`  \n",
    "- **Description:** Folders where PDAL will write each tiled `.las`/`.laz`. The script will create these directories if they don’t already exist. This is where the laz files get stored for each of the years based on the intersecting data.\n",
    "\n",
    "#### 6. Tiling & Reprojection Parameters\n",
    "- **Variables:**  \n",
    "  - `tile_size` – side length of each square tile (in meters).  \n",
    "  - `buffer_size` – extra margin around each tile (in meters) to guarantee overlap.  \n",
    "  - `target_epsg` – output coordinate system code (e.g. `\"EPSG:32610\"` for UTM Zone 10 N).  \n",
    "- **Adjust as needed** for your study area’s scale, overlap tolerance, and desired CRS.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42d8aa1-c69d-4a98-abe8-c793f8ab743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Connect to local google drive when opened in colab\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/gdrive/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222c39f1-4d61-4ce4-be29-628059535791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input GeoJSON with USGS 3DEP boundaries (EPSG:4326)\n",
    "boundaries_geojson = r\"C:/Users/sreeja/Documents/OpenForest4D/usgs_3dep_boundaries.geojson\"\n",
    "\n",
    "# Feature names matching the 'name' column in the GeoJSON\n",
    "name_a = \"CA PlacerCo 2012\"\n",
    "name_b = \"USGS LPC CA NoCAL Wildfires B5a 2018\"\n",
    "\n",
    "# Path to save the computed intersection\n",
    "intersection_geojson = r\"C:/Users/sreeja/Documents/CA_Placer_Co/sc_intersection.geojson\"\n",
    "\n",
    "# EPT endpoints for each dataset\n",
    "ept_path_a = \"ept://https://s3-us-west-2.amazonaws.com/usgs-lidar-public/CA_PlacerCo_2012\"\n",
    "ept_path_b = \"ept://https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_NoCAL_Wildfires_B5a_2018\"\n",
    "\n",
    "# Output directories for tiles\n",
    "output_dir_a = r\"C:/Users/sreeja/Documents/CA_Placer_Co/Placer_2012_Tiled\"\n",
    "output_dir_b = r\"C:/Users/sreeja/Documents/CA_Placer_Co/Placer_2018_Tiled\"\n",
    "\n",
    "# Tiling parameters and target CRS\n",
    "tile_size = 1000      # meters\n",
    "buffer_size = 20      # meters\n",
    "target_epsg = \"EPSG:32610\"  # UTM Zone 10N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9c8eef-1f96-4935-befa-996340557a18",
   "metadata": {},
   "source": [
    "##  3. Imports & Function Definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feddc0d0-dd53-4e92-8f40-a6260500ab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "from pyproj import Transformer\n",
    "import pdal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239f61c0-739e-4579-9a37-ad7617986ddb",
   "metadata": {},
   "source": [
    "# Function to compute intersection of two named features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ba34481-1e33-48dc-8303-0f2070489366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_intersection(geojson_path: str, feature1: str, feature2: str, out_path: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Read a boundary GeoJSON, select two named features, compute their spatial intersection,\n",
    "    save it to a new GeoJSON, and return the intersection bounding box.\n",
    "\n",
    "    Args:\n",
    "        geojson_path: Path to input GeoJSON (EPSG:4326).\n",
    "        feature1: Exact name of the first feature.\n",
    "        feature2: Exact name of the second feature.\n",
    "        out_path: Path to save the intersection GeoJSON.\n",
    "\n",
    "    Returns:\n",
    "        Tuple (xmin, ymin, xmax, ymax) in EPSG:4326.\n",
    "    \"\"\"\n",
    "    gdf = gpd.read_file(geojson_path)\n",
    "    a = gdf[gdf['name'] == feature1]\n",
    "    b = gdf[gdf['name'] == feature2]\n",
    "    if a.empty or b.empty:\n",
    "        raise ValueError(f\"Features not found: {feature1}, {feature2}\")\n",
    "\n",
    "    if a.crs != b.crs:\n",
    "        b = b.to_crs(a.crs)\n",
    "\n",
    "    inter = gpd.overlay(a, b, how='intersection')\n",
    "    if inter.empty:\n",
    "        raise RuntimeError(\"No spatial overlap between features.\")\n",
    "\n",
    "    inter.to_file(out_path, driver='GeoJSON')\n",
    "    print(f\"Intersection saved to: {out_path}\")\n",
    "    return tuple(inter.total_bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07033ebe-9078-4acb-b448-e5a403f8ba3e",
   "metadata": {},
   "source": [
    "# Function to tile and download EPT lidar\n",
    "\n",
    "The download_ept_tiles function encapsulates a complete workflow for chopping up a large lidar data footprint into manageable tiles and downloading just the points that are needed, reprojecting and saving each tile as a compressed LAS/LAZ. Here’s how it works, step by step:\n",
    "\n",
    "1. **Preparing the Output Folder**\n",
    "As soon a the function is called, it ensures that your designated output directory exists by calling os.makedirs(output_dir, exist_ok=True). This means you don’t have to worry about creating folders yourself, if it isn’t there, Python will make it for you.\n",
    "\n",
    "2. **Reprojecting Your Geographic Bounds**\n",
    "The function takes your WGS84 \"bounds\" (a 4‑tuple of longitudes and latitudes in EPSG:4326) and uses a PROJ transformer (via pyproj.Transformer) to convert those corner coordinates into your target_epsg projection (for example, UTM Zone 10N). All downstream tiling happens in this projected CRS so that distances (tile sizes and buffers) in meters map directly to the grid.\n",
    "\n",
    "3. **Snapping to a Regular Tile Grid**\n",
    "Once your minimum and maximum X/Y in the target CRS are known, the code snaps those values to the nearest multiple of tile_size. For example, if your data spans from 512 m to 3852 m eastings, and you use 1000 m tiles, the loop will start at 0 m and run tiles at [0–1000], [1000–2000], [2000–3000], and [3000–4000 m]. This guarantees that every tile is the same size and that the full extent CAN BE COVERES (plus a tile’s worth of extra margin at the edges).\n",
    "\n",
    "4. **Looping over Every Tile**\n",
    "Two nested while loops iterate over every grid cell:\n",
    " - The outer loop increments Y by tile_size\n",
    " - The inner loop increments X by tile_size\n",
    "For each cell, it builds a unique tile_id string like \"3000_2000\" representing the lower‑left corner of that square.\n",
    "\n",
    "5. **Skipping Already-Downloaded Tiles**\n",
    "Before doing any heavy work, the function checks if tile_id.laz already exists in your output directory. If so, it prints a \"Skipping existing tile\" message and moves on. This lets you safely re‑run the notebook without re‑downloading data you already have.\n",
    "\n",
    "6. **Applying a Buffer**\n",
    "Each tile is optionally expanded by buffer meters on all sides (so a 1040 m square is requested if a 20 m buffer is used for a 1000 m tile). Buffers are crucial to avoid edge artifacts when interpolating or merging later on.\n",
    "\n",
    "7. **Building a PDAL Pipeline**\n",
    "For each tile, the function builds a small JSON‐style PDAL pipeline:\n",
    "\n",
    " - `readers.ept` points at your EPT URL and restricts the request to the buffered bounds.\n",
    " - `filters.reprojection` immediately reprojects those points into your target_epsg CRS.\n",
    " - `writers.las` writes out a compressed LAS/LAZ file, named by the tile_id.\n",
    "\n",
    "8. **Executing & Checking Point Counts**\n",
    "The PDAL pipeline is executed via p.execute(). That returns the number of points read for that tile.\n",
    " - If count > 0, the file stays on disk and you see a \"Downloaded X points\" message.\n",
    " - If count == 0, the code removes the empty file (so thousands of zero‑point tiles are not accumulated) and logs \"No points for tile …; file skipped.\"\n",
    "\n",
    "9. * Timing & Reporting**\n",
    "Finally, the function keeps track of total elapsed time across all tiles (with time.time() before and after the loops) and prints a summary like\n",
    "`Completed downloading tiles to C:/…/Placer_2012_Tiled in 123.4 seconds`.\n",
    "\n",
    "##### Why each step matters\n",
    "\n",
    " - Regular tiling ensures that your downstream analyses (DEM generation, classification, etc.) can be parallelized and that no tile is too large for memory.\n",
    " - Buffers prevent edge‐of‐tile artifacts when filters look at neighboring points.\n",
    " - Reprojection guarantees that all point files share the same coordinate system and spatial resolution.\n",
    " - Compressed output (LAZ vs. LAS) saves disk space and I/O time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1557a53a-7883-43f5-9686-55aee9b4d5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_ept_tiles(ept_url: str, output_dir: str, bounds: tuple,\n",
    "                       tile_size: int, buffer: int, target_epsg: str):\n",
    "    \"\"\"\n",
    "    Tile a WGS84 bounding box, download lidar from an EPT endpoint for each tile,\n",
    "    reproject to the target CRS, and save as compressed .laz files, skipping any\n",
    "    tiles that contain zero points.\n",
    "\n",
    "    Args:\n",
    "        ept_url: EPT endpoint URL.\n",
    "        output_dir: Directory to save the output tiles.\n",
    "        bounds: Tuple (xmin, ymin, xmax, ymax) in EPSG:4326.\n",
    "        tile_size: Tile dimension in meters.\n",
    "        buffer: Buffer around each tile in meters.\n",
    "        target_epsg: Output projection (e.g., 'EPSG:32610').\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Project the WGS84 bounds into the target CRS\n",
    "    transformer = Transformer.from_crs('EPSG:4326', target_epsg, always_xy=True)\n",
    "    x0, y0 = transformer.transform(bounds[0], bounds[1])\n",
    "    x1, y1 = transformer.transform(bounds[2], bounds[3])\n",
    "\n",
    "    # Snap to the tile grid\n",
    "    min_x = int(x0 // tile_size) * tile_size\n",
    "    min_y = int(y0 // tile_size) * tile_size\n",
    "    max_x = int(x1 // tile_size + 1) * tile_size\n",
    "    max_y = int(y1 // tile_size + 1) * tile_size\n",
    "\n",
    "    print(f\"Downloading tiles from X:{min_x}-{max_x}, Y:{min_y}-{max_y} in {target_epsg}\")\n",
    "\n",
    "    start = time.time()\n",
    "    y = min_y\n",
    "    while y < max_y:\n",
    "        x = min_x\n",
    "        while x < max_x:\n",
    "            tile_id = f\"{x}_{y}\"\n",
    "            out_file = os.path.join(output_dir, f\"{tile_id}.laz\")\n",
    "\n",
    "            if os.path.isfile(out_file):\n",
    "                print(f\"Skipping existing tile: {tile_id}\")\n",
    "                x += tile_size\n",
    "                continue\n",
    "\n",
    "            # Build the buffered bounds string for PDAL\n",
    "            bx0, bx1 = x - buffer, x + tile_size + buffer\n",
    "            by0, by1 = y - buffer, y + tile_size + buffer\n",
    "            bounds_str = f\"([{bx0},{bx1}], [{by0},{by1}])/{target_epsg}\"\n",
    "\n",
    "            pipeline = {\n",
    "                'pipeline': [\n",
    "                    {'type': 'readers.ept',        'filename': ept_url, 'bounds': bounds_str},\n",
    "                    {'type': 'filters.reprojection', 'out_srs': target_epsg},\n",
    "                    {'type': 'writers.las',        'filename': out_file, 'compression': 'laszip'}\n",
    "                ]\n",
    "            }\n",
    "\n",
    "            try:\n",
    "                p = pdal.Pipeline(json.dumps(pipeline))\n",
    "                count = p.execute()\n",
    "                if count > 0:\n",
    "                    print(f\"Downloaded {count} points for tile {tile_id}\")\n",
    "                else:\n",
    "                    # Remove the empty file and skip\n",
    "                    if os.path.exists(out_file):\n",
    "                        os.remove(out_file)\n",
    "                    print(f\"No points for tile {tile_id}; file skipped.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error on tile {tile_id}: {e}\")\n",
    "\n",
    "            x += tile_size\n",
    "        y += tile_size\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"Completed downloading tiles to {output_dir} in {elapsed:.1f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca7ef2cc-e53c-43e8-a969-febd85b8060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the intersection polygon in EPSG:4326\n",
    "bounds_4326 = compute_intersection(\n",
    "    boundaries_geojson, name_a, name_b, intersection_geojson\n",
    ")\n",
    "\n",
    "# # Download & tile the EPT point cloud for Dataset A\n",
    "download_ept_tiles(ept_path_a, output_dir_a, bounds_4326, tile_size, buffer_size, target_epsg)\n",
    "\n",
    "#Repeat for Dataset B\n",
    "download_ept_tiles(ept_path_b, output_dir_b, bounds_4326, tile_size, buffer_size, target_epsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1a28f4-212b-44e7-9a70-20c86fc3cb3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
